# Copyright xmuspeech (Author: Leo 2022-01-23)
feat_dim: 80 # the num_mel_bins of fbank and the num_ceps of mfcc
data_type: 'shard'  # shard or raw
num_targets: 5994   # 1211 5994

model_type: "resnet" # "tdnn" "resnet" "ecapa"
#model_blueprint: "AL_SRE/model/TDNN.py" ##TDNN.py
#model_blueprint: "AL_SRE/model/snowdar_xvector.py"
model_blueprint: "AL_SRE/model/resnet_xvector_ppl.py"
# feature extraction
dataset_conf:
    # random_chunk
    split_wav: false
    random_chunk: true
    random_chunk_size: 2.015
    # resample
    resample: false
    resample_conf:
        resample_rate: 16000
    # de_silence
    de_silence: false #true false
    de_sil_conf:
        win_len: 0.1
        min_eng: 50
        retry_times: 1
        force_output: true

    # waveform true config
    speech_aug: true #false #true
    speech_aug_conf: "AL_SRE/config/speech_aug_random.yaml"
#    csv_aug_folder: ''
    csv_aug_folder: "exp/aug_csv"
    # It seems exit some bug, DO NOT set dither and use_energy together.
    feature_extraction_conf:
        feature_type: 'fbank'
        kaldi_featset:
            num_mel_bins: 80
            frame_shift: 10
            frame_length: 25
            low_freq: 40
            high_freq: -200
            energy_floor: 0.0
            use_energy: false

        mean_var_conf:
            mean_norm: true
            std_norm: false

#        seg_len: 400

    # spec level config
    spec_aug: false
    spec_aug_conf:
        aug: specaugment # None or specaugment
        aug_params:
            frequency: 0.2
            frame: 0.2
            rows: 4
            cols: 4
            random_rows: true
            random_cols: true


    shuffle: true
    shuffle_conf:
        shuffle_size: 3500
    batch_conf:
        batch_type: 'static' # static or dynamic
        batch_size: 60

# attention: Do not specify batch size in dataloader.
data_loader_conf:
    batch_size: 200
    shuffle: true
    num_workers: 4
    pin_memory: false
    use_fast_loader: true #false
    max_prefetch: 10
    drop_last: true
#data_loader_conf:
#    batch_size: 200
#    num_workers: 4
#    pin_memory: false
#    prefetch_factor: 100 # pf(400) * bs(16) is about 2 shards which has 3000 samples each.
